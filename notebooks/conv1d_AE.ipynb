{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "033fdad7",
   "metadata": {},
   "source": [
    "# Conv1d_Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff55f063",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:18:50.321961Z",
     "start_time": "2022-10-06T05:18:38.988557Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "########################################################################\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# import additional python-library\n",
    "########################################################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import librosa.core\n",
    "import librosa.feature\n",
    "import librosa.display\n",
    "import yaml\n",
    "import pathlib\n",
    "import optuna\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import warnings\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# from import\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "from dataset import Mimii_due, Toyadmos\n",
    "import preprocess as preproc\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81af9cc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:18:50.337521Z",
     "start_time": "2022-10-06T05:18:50.321961Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97926bdf",
   "metadata": {},
   "source": [
    "## 1D Feature representation - amplitude values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b1520b",
   "metadata": {},
   "source": [
    "### Dataset MIMII_DUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13781ace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:18:50.353534Z",
     "start_time": "2022-10-06T05:18:50.338526Z"
    }
   },
   "outputs": [],
   "source": [
    "# train data dir\n",
    "target_dir = r'datasets\\MIMII_DUE\\dev_data\\gearbox'\n",
    "section_name = 'section_00'\n",
    "dir_name_train = r'\\train'\n",
    "# target_test data dir\n",
    "dir_name_test = r'\\target_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2f1310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:19:32.068505Z",
     "start_time": "2022-10-06T05:18:50.355535Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1004/1004 [00:34<00:00, 28.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 204/204 [00:07<00:00, 29.03it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_train_mimii_ts = Mimii_due(target_dir, section_name, dir_name_train, extraction_type='amplitude')\n",
    "dataset_test_mimii_ts = Mimii_due(target_dir, section_name, dir_name_test, extraction_type='amplitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45730dad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:19:32.084508Z",
     "start_time": "2022-10-06T05:19:32.070506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1004, 160000), (204, 160000), (1004,), (204,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mimii_ts, y_train_mimii_ts = dataset_train_mimii_ts.data, dataset_train_mimii_ts.labels\n",
    "X_test_mimii_ts, y_test_mimii_ts = dataset_test_mimii_ts.data, dataset_test_mimii_ts.labels\n",
    "X_train_mimii_ts.shape, X_test_mimii_ts.shape, y_train_mimii_ts.shape, y_test_mimii_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "988472c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:19:32.100512Z",
     "start_time": "2022-10-06T05:19:32.085509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mimii_due_anomaly ratio = 0.53\n"
     ]
    }
   ],
   "source": [
    "# Anomaly data ratio\n",
    "contamination_mimii = np.round(y_test_mimii_ts.sum() / y_test_mimii_ts.shape, 2)\n",
    "print(f'Mimii_due_anomaly ratio = {contamination_mimii[0]}')\n",
    "contamination_mimii = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae874248",
   "metadata": {},
   "source": [
    "### Dataset ToyAdmos2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "895a2504",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:19:32.116516Z",
     "start_time": "2022-10-06T05:19:32.101513Z"
    }
   },
   "outputs": [],
   "source": [
    "# data dir\n",
    "target_dir_toyadm = r'datasets\\ToyAdmos2'\n",
    "dir_name_toyadm_anomaly = r'\\toyad2_car_A_anomaly'\n",
    "dir_name_toyadm_normal = r'\\toyad2_car_A1_normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d1e7c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:06.042491Z",
     "start_time": "2022-10-06T05:19:32.118517Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3545/3545 [11:33<00:00,  5.11it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_toy_ts = Toyadmos(target_dir_toyadm, dir_name_toyadm_normal, dir_name_toyadm_anomaly, extraction_type='amplitude')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "707836fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:25.174458Z",
     "start_time": "2022-10-06T05:31:06.043491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2871, 192000), (319, 192000), (355, 192000), (2871,), (319,), (355,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train - test - val stratified split\n",
    "X_train_toy_ts, X_test_toy_ts, X_val_toy_ts, y_train_toy_ts, y_test_toy_ts, y_val_toy_ts = preproc.mix_data(\n",
    "    [dataset_toy_ts.data], [dataset_toy_ts.labels])\n",
    "X_train_toy_ts.shape, X_test_toy_ts.shape, X_val_toy_ts.shape, y_train_toy_ts.shape, y_test_toy_ts.shape, y_val_toy_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d368db48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:25.230093Z",
     "start_time": "2022-10-06T05:31:25.192829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToyAdmos anomaly ratio = 0.23\n"
     ]
    }
   ],
   "source": [
    "# Anomaly data ratio\n",
    "contamination_toy = np.round(y_test_toy_ts.sum() / y_test_toy_ts.shape, 2)\n",
    "print(f'ToyAdmos anomaly ratio = {contamination_toy[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e3a94c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:25.379049Z",
     "start_time": "2022-10-06T05:31:25.230093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "223e690f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:25.416778Z",
     "start_time": "2022-10-06T05:31:25.379049Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataloader(X_train, y_train, X_test, y_test, batch_size):\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train.astype(\n",
    "        np.float32)), torch.tensor(y_train.astype(np.long)))\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataset = TensorDataset(\n",
    "        torch.tensor(X_test.astype(np.float32)),\n",
    "        torch.tensor(y_test.astype(np.long)))\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "289b81f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:25.459529Z",
     "start_time": "2022-10-06T05:31:25.416778Z"
    }
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    '''\n",
    "    https://github.com/L1aoXingyu/pytorch-beginner/blob/master/08-AutoEncoder/conv_autoencoder.py\n",
    "    '''\n",
    "    def __init__(self, input_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 8, 3, stride=1, padding=1), # output_size = input_size\n",
    "            nn.MaxPool1d(4,4), # output_size = input_size / 4\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(8, 16, 3, stride=1, padding=1),  # output_size = input_size / 4 \n",
    "            nn.MaxPool1d(4,4),  # output_size = input_size / 16\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(16, 32, 3, stride=1, padding=1),  # output_size = input_size /16\n",
    "            nn.MaxPool1d(4,4),  # output_size = input_size / 64\n",
    "            nn.ReLU(True),\n",
    "            nn.Flatten(start_dim=1),\n",
    "           \n",
    "            nn.Linear(int((input_size/64)*32), 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 100)\n",
    "            \n",
    "            \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(100, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, int(input_size/64)*32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(dim=1, unflattened_size=(32, int(input_size/64))),\n",
    "            #nn.MaxUnpool1d(4,4),\n",
    "            nn.ConvTranspose1d(32, 16, 3, stride=4, padding=0, output_padding=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            #nn.MaxUnpool1d(4,4),\n",
    "            nn.ConvTranspose1d(16, 8, 3, stride=4, padding=0, output_padding=1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(True),\n",
    "            #nn.MaxUnpool1d(4,4),\n",
    "            nn.ConvTranspose1d(8, 1, 3, stride=4, \n",
    "            padding=0, output_padding=1)\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder = self.encoder(x)\n",
    "        x = self.decoder(encoder)\n",
    "        return x, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9e49918",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:25.480872Z",
     "start_time": "2022-10-06T05:31:25.459529Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_score_distribution(model, data_loader, criterion, save_to=None, figsize=(8, 6), epoch=0):\n",
    "    losses = []\n",
    "    labels = []\n",
    "    for (x_batch, y_batch) in data_loader:\n",
    "        x_batch = x_batch.cuda()\n",
    "\n",
    "        output = model(x_batch)\n",
    "        loss = criterion(output, x_batch)\n",
    "\n",
    "        loss = torch.mean(loss, dim=1)\n",
    "        loss = loss.detach().cpu().numpy().flatten()\n",
    "        losses.append(loss)\n",
    "\n",
    "        labels.append(y_batch.detach().cpu().numpy().flatten())\n",
    "\n",
    "    losses = np.concatenate(losses)\n",
    "    labels = np.concatenate(labels)\n",
    "\n",
    "    losses_0 = losses[labels == 0]\n",
    "    losses_1 = losses[labels == 1]\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=figsize)\n",
    "\n",
    "    ax.boxplot([losses_0, losses_1])\n",
    "    ax.set_xticklabels(['normal', 'anomaly'])\n",
    "    if epoch == 1 or epoch == 99:\n",
    "        plt.show()\n",
    "    plt.savefig(save_to)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85eda6a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:25.502022Z",
     "start_time": "2022-10-06T05:31:25.480872Z"
    }
   },
   "outputs": [],
   "source": [
    "# using difference between input & output we can get anomaly score\n",
    "# (anomaly samples has higher difference between input and output then normal samples)\n",
    "def get_difference_score(model, x, batch_size, extraction_type='melspectrogram'):\n",
    "\n",
    "    dataset = TensorDataset(torch.tensor(x.astype(np.float32)))\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    predictions = []\n",
    "    for (x_batch, ) in data_loader:\n",
    "        x_batch = x_batch.cuda()\n",
    "        preds = model(x_batch)\n",
    "        predictions.append(preds[0].detach().cpu().numpy())\n",
    "\n",
    "    predictions = np.concatenate(predictions)\n",
    "    \n",
    "    \n",
    "    if extraction_type != 'melspectrogram':\n",
    "        predictions = predictions.reshape(predictions.shape[0], predictions.shape[2])\n",
    "        x=x.reshape(x.shape[0], x.shape[2])\n",
    "        print(predictions.shape)\n",
    "        print(x.shape)\n",
    "        diff = ((x**2 - predictions**2)).mean(axis=1).reshape(-1, 1)\n",
    "    else:\n",
    "        \n",
    "        \n",
    "        diff = (x.mean(axis=2) - predictions.mean(axis=2)\n",
    "                ).reshape(x.shape[0], x.shape[-1])\n",
    "\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0798e9f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:25.532228Z",
     "start_time": "2022-10-06T05:31:25.502022Z"
    }
   },
   "outputs": [],
   "source": [
    "def autoencoder_test(X_train, X_test, X_val, y_train, y_test, y_val, batch_size=64, lr=1e-3, epochs=10, extraction_type='aggregate_MFCC'):\n",
    "    epochs = epochs\n",
    "    input_size = X_test.shape[-1]\n",
    "    model = Autoencoder(input_size).cuda()\n",
    "    criterion = nn.MSELoss()\n",
    "    per_sample_criterion = nn.MSELoss(reduction=\"none\")\n",
    "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    plot_path = r'plots'\n",
    "    \n",
    "    X_train =  X_train[:, np.newaxis, :]\n",
    "    X_test = X_test[:, np.newaxis, :]\n",
    "    X_val = X_val[:, np.newaxis, :]\n",
    "    train_loader, test_loader = dataloader(\n",
    "            X_train, y_train, X_test, y_test, batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for (x_batch, _) in train_loader:\n",
    "            x_batch = x_batch.cuda()\n",
    "\n",
    "            output = model(x_batch)\n",
    "            loss = criterion(output[0], x_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(\"epoch [{}/{}], train loss:{:.4f}\".format(epoch +\n",
    "              1, epochs, running_loss))\n",
    "        #if extraction_type != 'melspectrogram':\n",
    "            #save_score_distribution(\n",
    "               # model, test_loader, per_sample_criterion, plot_path, epoch=epoch)\n",
    "\n",
    "    #test_score = get_difference_score(\n",
    "    #    model, X_test, batch_size, extraction_type=extraction_type)\n",
    "    test_score = get_difference_score(\n",
    "        model, X_test, batch_size, extraction_type=extraction_type)\n",
    "\n",
    "\n",
    "    # using classification algorithms we can classify samples by outier score (difference between input and output)\n",
    "    score_forest = RandomForestClassifier(max_features=100, random_state=0)\n",
    "    score_forest.fit(test_score, y_test)\n",
    "\n",
    "    # Classification report on Validation data\n",
    "    val_score = get_difference_score(\n",
    "        model, X_val, batch_size, extraction_type=extraction_type)\n",
    "    \n",
    "    print(preproc.PyOD_classification_report(test_score, val_score, y_train,\n",
    "                                             y_val, dataset='MIMII_DUE', extraction_type=extraction_type, contamination=contamination_mimii))\n",
    "\n",
    "    \n",
    "    prediction = score_forest.predict(val_score)\n",
    "    accuracy = metrics.accuracy_score(y_val, prediction)\n",
    "    precision = metrics.precision_score(y_val, prediction)\n",
    "    recall = metrics.recall_score(y_val, prediction)\n",
    "    f1_score = metrics.f1_score(y_val, prediction)\n",
    "    scores = pd.DataFrame(\n",
    "        [{'Extraction_type': extraction_type, 'Model_name': 'Autoencoder', 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1_score': f1_score}])\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf0e305a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:29.427370Z",
     "start_time": "2022-10-06T05:31:25.534228Z"
    }
   },
   "outputs": [],
   "source": [
    "# train-test-val from MIMII_DUE_ts dataset\n",
    "X_train_mimii_ts, X_test_mimii_ts, X_val_mimii_ts, y_train_mimii, y_test_mimii, y_val_mimii = preproc.mix_data(\n",
    "    [X_train_mimii_ts, X_test_mimii_ts], [y_train_mimii_ts, y_test_mimii_ts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24a3d9dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:32:52.115577Z",
     "start_time": "2022-10-06T05:31:29.427370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/50], train loss:5.7605\n",
      "epoch [2/50], train loss:3.0557\n",
      "epoch [3/50], train loss:2.1364\n",
      "epoch [4/50], train loss:1.6573\n",
      "epoch [5/50], train loss:1.3285\n",
      "epoch [6/50], train loss:1.0816\n",
      "epoch [7/50], train loss:0.8943\n",
      "epoch [8/50], train loss:0.7610\n",
      "epoch [9/50], train loss:0.6662\n",
      "epoch [10/50], train loss:0.5855\n",
      "epoch [11/50], train loss:0.5178\n",
      "epoch [12/50], train loss:0.4540\n",
      "epoch [13/50], train loss:0.4084\n",
      "epoch [14/50], train loss:0.3656\n",
      "epoch [15/50], train loss:0.3381\n",
      "epoch [16/50], train loss:0.3302\n",
      "epoch [17/50], train loss:0.3096\n",
      "epoch [18/50], train loss:0.2792\n",
      "epoch [19/50], train loss:0.2579\n",
      "epoch [20/50], train loss:0.2380\n",
      "epoch [21/50], train loss:0.2264\n",
      "epoch [22/50], train loss:0.2124\n",
      "epoch [23/50], train loss:0.1999\n",
      "epoch [24/50], train loss:0.1909\n",
      "epoch [25/50], train loss:0.1800\n",
      "epoch [26/50], train loss:0.3246\n",
      "epoch [27/50], train loss:0.1914\n",
      "epoch [28/50], train loss:0.1621\n",
      "epoch [29/50], train loss:0.1496\n",
      "epoch [30/50], train loss:0.1391\n",
      "epoch [31/50], train loss:0.1316\n",
      "epoch [32/50], train loss:0.1235\n",
      "epoch [33/50], train loss:0.1171\n",
      "epoch [34/50], train loss:0.1121\n",
      "epoch [35/50], train loss:0.1052\n",
      "epoch [36/50], train loss:0.0999\n",
      "epoch [37/50], train loss:0.0941\n",
      "epoch [38/50], train loss:0.0894\n",
      "epoch [39/50], train loss:0.0850\n",
      "epoch [40/50], train loss:0.0815\n",
      "epoch [41/50], train loss:0.0778\n",
      "epoch [42/50], train loss:0.0731\n",
      "epoch [43/50], train loss:0.0693\n",
      "epoch [44/50], train loss:0.0654\n",
      "epoch [45/50], train loss:0.0620\n",
      "epoch [46/50], train loss:0.0590\n",
      "epoch [47/50], train loss:0.0563\n",
      "epoch [48/50], train loss:0.0536\n",
      "epoch [49/50], train loss:0.0517\n",
      "epoch [50/50], train loss:0.0487\n",
      "(109, 160000)\n",
      "(109, 160000)\n",
      "(121, 160000)\n",
      "(121, 160000)\n",
      "  Model_name  F1_score    Dataset  Accuracy  Precision Extraction_type  \\\n",
      "0    IForest  0.178218  MIMII_DUE  0.314050   0.100000       amplitude   \n",
      "0        LOF  0.141176  MIMII_DUE  0.396694   0.081081       amplitude   \n",
      "0      OCSVM  0.071429  MIMII_DUE  0.785124   0.058824       amplitude   \n",
      "\n",
      "     Recall  \n",
      "0  0.818182  \n",
      "0  0.545455  \n",
      "0  0.090909  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extraction_type</th>\n",
       "      <th>Model_name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amplitude</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.917355</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Extraction_type   Model_name  Accuracy  Precision    Recall  F1_score\n",
       "0       amplitude  Autoencoder  0.917355        0.6  0.272727     0.375"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MIMII_DUE Anomaly detection using Autoencoders (amplitude)\n",
    "mimii_AE_ts = autoencoder_test(X_train_mimii_ts, X_test_mimii_ts, X_val_mimii_ts, y_train_mimii, y_test_mimii,\n",
    "                                 y_val_mimii, batch_size=64, lr=1e-3, epochs=50, extraction_type='amplitude')\n",
    "mimii_AE_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46ed5bf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:37:17.960624Z",
     "start_time": "2022-10-06T05:32:52.119578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/50], train loss:7.0474\n",
      "epoch [2/50], train loss:2.1074\n",
      "epoch [3/50], train loss:1.1781\n",
      "epoch [4/50], train loss:0.6588\n",
      "epoch [5/50], train loss:0.4030\n",
      "epoch [6/50], train loss:0.2984\n",
      "epoch [7/50], train loss:0.2484\n",
      "epoch [8/50], train loss:0.2138\n",
      "epoch [9/50], train loss:0.1824\n",
      "epoch [10/50], train loss:0.1583\n",
      "epoch [11/50], train loss:0.1374\n",
      "epoch [12/50], train loss:0.1193\n",
      "epoch [13/50], train loss:0.1037\n",
      "epoch [14/50], train loss:0.0904\n",
      "epoch [15/50], train loss:0.0796\n",
      "epoch [16/50], train loss:0.0715\n",
      "epoch [17/50], train loss:0.0637\n",
      "epoch [18/50], train loss:0.0572\n",
      "epoch [19/50], train loss:0.0526\n",
      "epoch [20/50], train loss:0.0489\n",
      "epoch [21/50], train loss:0.0456\n",
      "epoch [22/50], train loss:0.0429\n",
      "epoch [23/50], train loss:0.0409\n",
      "epoch [24/50], train loss:0.0394\n",
      "epoch [25/50], train loss:0.0380\n",
      "epoch [26/50], train loss:0.0369\n",
      "epoch [27/50], train loss:0.0360\n",
      "epoch [28/50], train loss:0.0352\n",
      "epoch [29/50], train loss:0.0345\n",
      "epoch [30/50], train loss:0.0341\n",
      "epoch [31/50], train loss:0.0337\n",
      "epoch [32/50], train loss:0.0335\n",
      "epoch [33/50], train loss:0.0332\n",
      "epoch [34/50], train loss:0.0331\n",
      "epoch [35/50], train loss:0.0329\n",
      "epoch [36/50], train loss:0.0327\n",
      "epoch [37/50], train loss:0.0326\n",
      "epoch [38/50], train loss:0.0324\n",
      "epoch [39/50], train loss:0.0323\n",
      "epoch [40/50], train loss:0.0323\n",
      "epoch [41/50], train loss:0.0323\n",
      "epoch [42/50], train loss:0.0321\n",
      "epoch [43/50], train loss:0.0321\n",
      "epoch [44/50], train loss:0.0320\n",
      "epoch [45/50], train loss:0.0320\n",
      "epoch [46/50], train loss:0.0319\n",
      "epoch [47/50], train loss:0.0319\n",
      "epoch [48/50], train loss:0.0319\n",
      "epoch [49/50], train loss:0.0319\n",
      "epoch [50/50], train loss:0.0320\n",
      "(319, 192000)\n",
      "(319, 192000)\n",
      "(355, 192000)\n",
      "(355, 192000)\n",
      "  Model_name  F1_score    Dataset  Accuracy  Precision Extraction_type  \\\n",
      "0    IForest  0.451411  MIMII_DUE  0.507042   0.302521       amplitude   \n",
      "0        LOF  0.447368  MIMII_DUE  0.526761   0.304933       amplitude   \n",
      "0      OCSVM  0.402985  MIMII_DUE  0.774648   0.509434       amplitude   \n",
      "\n",
      "     Recall  \n",
      "0  0.888889  \n",
      "0  0.839506  \n",
      "0  0.333333  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extraction_type</th>\n",
       "      <th>Model_name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amplitude</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.660377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Extraction_type   Model_name  Accuracy  Precision    Recall  F1_score\n",
       "0       amplitude  Autoencoder  0.797183   0.534351  0.864198  0.660377"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MIMII_DUE Anomaly detection using Autoencoders (amplitude)\n",
    "toy_AE_ts = autoencoder_test(X_train_toy_ts, X_test_toy_ts, X_val_toy_ts, y_train_toy_ts, y_test_toy_ts,\n",
    "                                 y_val_toy_ts, batch_size=64, lr=1e-3, epochs=50, extraction_type='amplitude')\n",
    "toy_AE_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c0e681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "34px",
    "width": "344px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "196px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
