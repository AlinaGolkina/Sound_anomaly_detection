{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "033fdad7",
   "metadata": {},
   "source": [
    "# Conv1d_Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff55f063",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:18:50.321961Z",
     "start_time": "2022-10-06T05:18:38.988557Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import yaml\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.path.pardir)))\n",
    "import anomaly_detection.preprocess as preproc\n",
    "from anomaly_detection.datasets import MimiiDue, ToyAdmos\n",
    "from anomaly_detection.models.conv1d_AE import Conv1dAE\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81af9cc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:18:50.337521Z",
     "start_time": "2022-10-06T05:18:50.321961Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97926bdf",
   "metadata": {},
   "source": [
    "## 1D Feature representation - amplitude values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b1520b",
   "metadata": {},
   "source": [
    "### Dataset MIMII_DUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13781ace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:18:50.353534Z",
     "start_time": "2022-10-06T05:18:50.338526Z"
    }
   },
   "outputs": [],
   "source": [
    "# train data dir\n",
    "target_dir = (\n",
    "    r\"C:\\Users\\alina\\OneDrive\\Документы\\Диплом\\datasets\\MIMII_DUE\\dev_data\\gearbox\"\n",
    ")\n",
    "section_name = \"section_00\"\n",
    "dir_name_train = r\"\\train\"\n",
    "# target_test data dir\n",
    "dir_name_test = r\"\\target_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da2f1310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:19:32.068505Z",
     "start_time": "2022-10-06T05:18:50.355535Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:37<00:00, 27.06it/s]\n",
      "100%|██████████| 204/204 [00:07<00:00, 27.51it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_train_mimii_ts = MimiiDue(\n",
    "    target_dir, section_name, dir_name_train, extraction_type=\"amplitude\"\n",
    ")\n",
    "dataset_test_mimii_ts = MimiiDue(\n",
    "    target_dir, section_name, dir_name_test, extraction_type=\"amplitude\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45730dad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:19:32.084508Z",
     "start_time": "2022-10-06T05:19:32.070506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1004, 160000), (204, 160000), (1004,), (204,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test from MIMII_DUE\n",
    "X_train_mimii_ts, y_train_mimii_ts = (\n",
    "    dataset_train_mimii_ts.data,\n",
    "    dataset_train_mimii_ts.labels,\n",
    ")\n",
    "X_test_mimii_ts, y_test_mimii_ts = (\n",
    "    dataset_test_mimii_ts.data,\n",
    "    dataset_test_mimii_ts.labels,\n",
    ")\n",
    "X_train_mimii_ts.shape, X_test_mimii_ts.shape, y_train_mimii_ts.shape, y_test_mimii_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988472c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:19:32.100512Z",
     "start_time": "2022-10-06T05:19:32.085509Z"
    }
   },
   "outputs": [],
   "source": [
    "# Anomaly data ratio\n",
    "contamination_mimii = np.round(y_test_mimii_ts.sum() / y_test_mimii_ts.shape, 2)\n",
    "print(f\"Mimii_due_anomaly ratio = {contamination_mimii[0]}\")\n",
    "contamination_mimii = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae874248",
   "metadata": {},
   "source": [
    "### Dataset ToyAdmos2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a2504",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:19:32.116516Z",
     "start_time": "2022-10-06T05:19:32.101513Z"
    }
   },
   "outputs": [],
   "source": [
    "# data dir\n",
    "target_dir_toyadm = r\"C:\\Users\\alina\\OneDrive\\Документы\\Диплом\\datasets\\ToyAdmos2\"\n",
    "dir_name_toyadm_anomaly = r\"\\toyad2_car_A_anomaly\"\n",
    "dir_name_toyadm_normal = r\"\\toyad2_car_A1_normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d1e7c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:06.042491Z",
     "start_time": "2022-10-06T05:19:32.118517Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_toy_ts = ToyAdmos(\n",
    "    target_dir_toyadm,\n",
    "    dir_name_toyadm_normal,\n",
    "    dir_name_toyadm_anomaly,\n",
    "    extraction_type=\"amplitude\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707836fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:25.174458Z",
     "start_time": "2022-10-06T05:31:06.043491Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train - test - val stratified split\n",
    "(\n",
    "    X_train_toy_ts,\n",
    "    X_test_toy_ts,\n",
    "    X_val_toy_ts,\n",
    "    y_train_toy_ts,\n",
    "    y_test_toy_ts,\n",
    "    y_val_toy_ts,\n",
    ") = preproc.mix_data([dataset_toy_ts.data], [dataset_toy_ts.labels])\n",
    "X_train_toy_ts.shape, X_test_toy_ts.shape, X_val_toy_ts.shape, y_train_toy_ts.shape, y_test_toy_ts.shape, y_val_toy_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d368db48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:25.230093Z",
     "start_time": "2022-10-06T05:31:25.192829Z"
    }
   },
   "outputs": [],
   "source": [
    "# Anomaly data ratio\n",
    "contamination_toy = np.round(y_test_toy_ts.sum() / y_test_toy_ts.shape, 2)\n",
    "print(f\"ToyAdmos anomaly ratio = {contamination_toy[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3a94c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:25.379049Z",
     "start_time": "2022-10-06T05:31:25.230093Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e690f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:25.416778Z",
     "start_time": "2022-10-06T05:31:25.379049Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataloader(X_train, y_train, X_test, y_test, batch_size):\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(X_train.astype(np.float32)), torch.tensor(y_train.astype(np.long))\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataset = TensorDataset(\n",
    "        torch.tensor(X_test.astype(np.float32)), torch.tensor(y_test.astype(np.long))\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e49918",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:25.480872Z",
     "start_time": "2022-10-06T05:31:25.459529Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_score_distribution(model, data_loader, criterion, figsize=(8, 6), epoch=0):\n",
    "    \"\"\"\n",
    "    plot losses for normal and anomaly samples\n",
    "\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    labels = []\n",
    "    for (x_batch, y_batch) in data_loader:\n",
    "        x_batch = x_batch.cuda()\n",
    "\n",
    "        output, enc = model(x_batch)\n",
    "        loss = criterion(output, x_batch)\n",
    "        loss = loss.reshape(loss.shape[0], loss.shape[2])\n",
    "        loss = torch.mean(loss, dim=1)\n",
    "        loss = loss.detach().cpu().numpy().flatten()\n",
    "        losses.append(loss)\n",
    "        labels.append(y_batch.detach().cpu().numpy().flatten())\n",
    "\n",
    "    losses = np.concatenate(losses)\n",
    "    labels = np.concatenate(labels)\n",
    "\n",
    "    losses_0 = losses[labels == 0]\n",
    "    losses_1 = losses[labels == 1]\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=figsize)\n",
    "\n",
    "    ax.boxplot([losses_0, losses_1])\n",
    "    ax.set_xticklabels([\"normal\", \"anomaly\"])\n",
    "    if epoch in [0, 9, 49, 99]:\n",
    "        plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eda6a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:25.502022Z",
     "start_time": "2022-10-06T05:31:25.480872Z"
    }
   },
   "outputs": [],
   "source": [
    "# using difference between input & output we can get anomaly score\n",
    "# (anomaly samples has higher difference between input and output then normal samples)\n",
    "def get_difference_score(model, x, batch_size, extraction_type=\"melspectrogram\"):\n",
    "    \"\"\"\n",
    "    return:\n",
    "       average difference between decoder output and input\n",
    "\n",
    "    \"\"\"\n",
    "    dataset = TensorDataset(torch.tensor(x.astype(np.float32)))\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    predictions = []\n",
    "    for (x_batch,) in data_loader:\n",
    "        x_batch = x_batch.cuda()\n",
    "        preds, enc = model(x_batch)\n",
    "        predictions.append(preds.detach().cpu().numpy())\n",
    "\n",
    "    predictions = np.concatenate(predictions)\n",
    "    if extraction_type != \"melspectrogram\":\n",
    "        predictions = predictions.reshape(predictions.shape[0], predictions.shape[2])\n",
    "        x = x.reshape(x.shape[0], x.shape[2])\n",
    "        diff = ((x**2 - predictions**2)).mean(axis=1).reshape(-1, 1)\n",
    "    else:\n",
    "\n",
    "        diff = (x.mean(axis=2) - predictions.mean(axis=2)).reshape(\n",
    "            x.shape[0], x.shape[-1]\n",
    "        )\n",
    "\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0798e9f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:25.532228Z",
     "start_time": "2022-10-06T05:31:25.502022Z"
    }
   },
   "outputs": [],
   "source": [
    "def autoencoder_test(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    X_val,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    y_val,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    epochs=10,\n",
    "    extraction_type=\"aggregate_MFCC\",\n",
    "):\n",
    "    epochs = epochs\n",
    "    input_size = X_test.shape[-1]\n",
    "    model = Conv1dAE(input_size).cuda()\n",
    "    criterion = nn.MSELoss()\n",
    "    per_sample_criterion = nn.MSELoss(reduction=\"none\")\n",
    "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    X_train = X_train[:, np.newaxis, :]\n",
    "    X_test = X_test[:, np.newaxis, :]\n",
    "    X_val = X_val[:, np.newaxis, :]\n",
    "    train_loader, test_loader = dataloader(X_train, y_train, X_test, y_test, batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for (x_batch, _) in train_loader:\n",
    "            x_batch = x_batch.cuda()\n",
    "\n",
    "            output, enc = model(x_batch)\n",
    "            loss = criterion(output[0], x_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(\"epoch [{}/{}], train loss:{:.4f}\".format(epoch + 1, epochs, running_loss))\n",
    "        # if extraction_type != 'melspectrogram':\n",
    "        save_score_distribution(model, test_loader, per_sample_criterion, epoch=epoch)\n",
    "\n",
    "    # test_score = get_difference_score(\n",
    "    #    model, X_test, batch_size, extraction_type=extraction_type)\n",
    "    test_score = get_difference_score(\n",
    "        model, X_test, batch_size, extraction_type=extraction_type\n",
    "    )\n",
    "\n",
    "    # using classification algorithms we can classify samples by outier score (difference between input and output)\n",
    "    score_forest = RandomForestClassifier(max_features=100, random_state=0)\n",
    "    score_forest.fit(test_score, y_test)\n",
    "\n",
    "    # Classification report on Validation data\n",
    "    val_score = get_difference_score(\n",
    "        model, X_val, batch_size, extraction_type=extraction_type\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        preproc.pyod_classification_report(\n",
    "            test_score,\n",
    "            val_score,\n",
    "            y_train,\n",
    "            y_val,\n",
    "            dataset=\"MIMII_DUE\",\n",
    "            extraction_type=extraction_type,\n",
    "            contamination=contamination_mimii,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    prediction = score_forest.predict(val_score)\n",
    "    accuracy = metrics.accuracy_score(y_val, prediction)\n",
    "    precision = metrics.precision_score(y_val, prediction)\n",
    "    recall = metrics.recall_score(y_val, prediction)\n",
    "    f1_score = metrics.f1_score(y_val, prediction)\n",
    "    scores = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"Extraction_type\": extraction_type,\n",
    "                \"Model_name\": \"Autoencoder\",\n",
    "                \"Accuracy\": accuracy,\n",
    "                \"Precision\": precision,\n",
    "                \"Recall\": recall,\n",
    "                \"F1_score\": f1_score,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e305a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:31:29.427370Z",
     "start_time": "2022-10-06T05:31:25.534228Z"
    }
   },
   "outputs": [],
   "source": [
    "# train-test-val from MIMII_DUE_ts dataset\n",
    "(\n",
    "    X_train_mimii,\n",
    "    X_test_mimii,\n",
    "    X_val_mimii,\n",
    "    y_train_mimii,\n",
    "    y_test_mimii,\n",
    "    y_val_mimii,\n",
    ") = preproc.mix_data(\n",
    "    [X_train_mimii_ts, X_test_mimii_ts], [y_train_mimii_ts, y_test_mimii_ts]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3d9dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:32:52.115577Z",
     "start_time": "2022-10-06T05:31:29.427370Z"
    }
   },
   "outputs": [],
   "source": [
    "# MIMII_DUE Anomaly detection using Autoencoders (amplitude)\n",
    "mimii_AE_ts = autoencoder_test(\n",
    "    X_train_mimii,\n",
    "    X_test_mimii,\n",
    "    X_val_mimii,\n",
    "    y_train_mimii,\n",
    "    y_test_mimii,\n",
    "    y_val_mimii,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    epochs=50,\n",
    "    extraction_type=\"amplitude\",\n",
    ")\n",
    "mimii_AE_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed5bf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T05:37:17.960624Z",
     "start_time": "2022-10-06T05:32:52.119578Z"
    }
   },
   "outputs": [],
   "source": [
    "# MIMII_DUE Anomaly detection using Autoencoders (amplitude)\n",
    "toy_AE_ts = autoencoder_test(\n",
    "    X_train_toy_ts,\n",
    "    X_test_toy_ts,\n",
    "    X_val_toy_ts,\n",
    "    y_train_toy_ts,\n",
    "    y_test_toy_ts,\n",
    "    y_val_toy_ts,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    epochs=50,\n",
    "    extraction_type=\"amplitude\",\n",
    ")\n",
    "toy_AE_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c0e681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('diploma')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "34px",
    "width": "344px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "196px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "ef6dcc2d7d4778f9111ae93647e5e977c9fe856fac0edf74c4de5ffddea4f9bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
